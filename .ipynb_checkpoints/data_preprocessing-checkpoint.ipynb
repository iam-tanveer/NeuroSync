{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df41c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import heartpy as hp\n",
    "from scipy.signal import butter, filtfilt, iirnotch, welch\n",
    "from scipy.integrate import simps\n",
    "import json\n",
    "import os\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'muse_data.npz'\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"Error: {file_path} not found.\")\n",
    "    print(\"Please make sure the .npz file is in the same directory as this script.\")\n",
    "else:\n",
    "    print(f\"Loading data from {file_path}...\")\n",
    "    data = np.load(file_path, allow_pickle=True)\n",
    "\n",
    "    # See what's inside\n",
    "    print(f\"\\nKeys in the .npz file: {list(data.keys())}\\n\")\n",
    "\n",
    "    # Extract the data streams\n",
    "    eeg_data = data['eeg.npy']\n",
    "    ppg_data = data['ppg.npy'].flatten() # Flatten to 1D array\n",
    "    acc_data = data['accel.npy']\n",
    "    gyro_data = data['gyro.npy']\n",
    "    timestamps = data['timestamp.npy']\n",
    "\n",
    "    # Extract metadata\n",
    "    # .item() is used to extract scalar/dict objects from 0-dim arrays\n",
    "    sampling_rates = data['sampling_rates.npy'].item()\n",
    "    channel_names = data['channel_names.npy']\n",
    "    duration_sec = data['duration_seconds.npy'].item()\n",
    "\n",
    "    eeg_sfreq = sampling_rates.get('eeg', 256) # Default to 256 if not found\n",
    "    ppg_sfreq = sampling_rates.get('ppg', 64)  # Default to 64 if not found\n",
    "\n",
    "    # Print a report\n",
    "    print(\"--- Data Report ---\")\n",
    "    print(f\"Duration: {duration_sec} seconds\")\n",
    "    print(f\"EEG Shape: {eeg_data.shape} (Samples, Channels)\")\n",
    "    print(f\"EEG Sampling Rate: {eeg_sfreq} Hz\")\n",
    "    print(f\"EEG Channel Names: {channel_names}\")\n",
    "    print(f\"PPG Shape: {ppg_data.shape} (Samples,)\")\n",
    "    print(f\"PPG Sampling Rate: {ppg_sfreq} Hz\")\n",
    "    print(f\"Accelerometer Shape: {acc_data.shape}\")\n",
    "    print(f\"Gyroscope Shape: {gyro_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac89c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_eeg(eeg_data, acc_data, gyro_data, sfreq, channel_names):\n",
    "    \"\"\"\n",
    "    Applies the full pre-processing pipeline to raw EEG data.\n",
    "    (Adapted to use provided channel names)\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Step 1: Baseline Removal and Re-referencing ---\n",
    "    eeg_referenced = eeg_data\n",
    "    if 'TP9' in channel_names and 'TP10' in channel_names:\n",
    "        try:\n",
    "            tp9_idx = np.where(channel_names == 'TP9')[0][0]\n",
    "            tp10_idx = np.where(channel_names == 'TP10')[0][0]\n",
    "            tp_avg = eeg_data[:, [tp9_idx, tp10_idx]].mean(axis=1, keepdims=True)\n",
    "            eeg_referenced = eeg_data - tp_avg\n",
    "            print(\"Re-referenced EEG to average of TP9 and TP10.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not re-reference: {e}. Using original data.\")\n",
    "            eeg_referenced = eeg_data\n",
    "    else:\n",
    "        print(\"TP9 or TP10 not found. Skipping re-referencing.\")\n",
    "\n",
    "    # --- Step 2: Filtering ---\n",
    "    bp_low = 1.0\n",
    "    bp_high = 45.0\n",
    "    nyquist = 0.5 * sfreq\n",
    "    b, a = butter(N=4, Wn=[bp_low/nyquist, bp_high/nyquist], btype='bandpass')\n",
    "    eeg_bandpassed = filtfilt(b, a, eeg_referenced, axis=0)\n",
    "\n",
    "    notch_freq = 50.0 \n",
    "    Q = 30\n",
    "    b_notch, a_notch = iirnotch(notch_freq, Q, fs=sfreq)\n",
    "    filtered_eeg = filtfilt(b_notch, a_notch, eeg_bandpassed, axis=0)\n",
    "\n",
    "    # --- Step 3: Artifact Removal ---\n",
    "    acc_mag = np.linalg.norm(acc_data, axis=1)\n",
    "    gyro_mag = np.linalg.norm(gyro_data, axis=1)\n",
    "\n",
    "    # Heuristic thresholds - these may need tuning!\n",
    "    acc_thresh = np.mean(acc_mag) + 3 * np.std(acc_mag)\n",
    "    gyro_thresh = np.mean(gyro_mag) + 3 * np.std(gyro_mag)\n",
    "    motion_mask = (acc_mag > acc_thresh) | (gyro_mag > gyro_thresh)\n",
    "\n",
    "    # Blink artifact detection (simple threshold on frontal channels)\n",
    "    blink_mask = np.zeros(filtered_eeg.shape[0], dtype=bool)\n",
    "    if 'AF7' in channel_names and 'AF8' in channel_names:\n",
    "        try:\n",
    "            af7_idx = np.where(channel_names == 'AF7')[0][0]\n",
    "            af8_idx = np.where(channel_names == 'AF8')[0][0]\n",
    "            frontal_diff = np.diff(filtered_eeg[:, [af7_idx, af8_idx]], axis=0, prepend=0)\n",
    "            blink_thresh_diff = 50 # 50 uV change in 1 sample\n",
    "            blink_mask = (np.abs(frontal_diff) > blink_thresh_diff).any(axis=1)\n",
    "            print(\"Calculated blink artifacts from AF7 and AF8.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not calculate blink artifacts: {e}\")\n",
    "    else:\n",
    "        print(\"AF7 or AF8 not in channels. Skipping blink detection.\")\n",
    "\n",
    "    artifact_mask = motion_mask | blink_mask\n",
    "    \n",
    "    # Expand mask slightly to cover edges of artifacts\n",
    "    # This is a simple 'dilation' operation\n",
    "    artifact_mask_expanded = np.convolve(artifact_mask, np.ones(int(sfreq * 0.5)), mode='same').astype(bool)\n",
    "    \n",
    "    return filtered_eeg, artifact_mask_expanded\n",
    "\n",
    "def extract_eeg_features(filtered_eeg, artifact_mask, sfreq, channel_names, epoch_sec, overlap_sec):\n",
    "    \"\"\"\n",
    "    Performs epoching and feature extraction (PSD band powers)\n",
    "    on the cleaned EEG data.\n",
    "    \"\"\"\n",
    "    BANDS = {\n",
    "        'delta': [1, 4],\n",
    "        'theta': [4, 8],\n",
    "        'alpha': [8, 12],\n",
    "        'beta': [12, 30],\n",
    "        'gamma': [30, 45]\n",
    "    }\n",
    "    \n",
    "    epoch_samples = int(epoch_sec * sfreq)\n",
    "    overlap_samples = int(overlap_sec * sfreq)\n",
    "    step_samples = epoch_samples - overlap_samples\n",
    "    \n",
    "    num_channels = filtered_eeg.shape[1]\n",
    "    clean_epochs = []\n",
    "    \n",
    "    for start in range(0, filtered_eeg.shape[0] - epoch_samples + 1, step_samples):\n",
    "        end = start + epoch_samples\n",
    "        \n",
    "        # --- Artifact Check ---\n",
    "        # Reject epoch if > 25% of it is an artifact\n",
    "        if artifact_mask[start:end].mean() > 0.25:\n",
    "            print(f\"Skipping epoch {start / sfreq:.2f}s (too many artifacts)\")\n",
    "            continue\n",
    "            \n",
    "        epoch_data = filtered_eeg[start:end, :]\n",
    "        epoch_features = {'start_time_sec': start / sfreq}\n",
    "        \n",
    "        for ch_idx in range(num_channels):\n",
    "            freqs, psd = welch(epoch_data[:, ch_idx], fs=sfreq, nperseg=epoch_samples)\n",
    "            ch_name = channel_names[ch_idx]\n",
    "            ch_features = {}\n",
    "            \n",
    "            for band, (low, high) in BANDS.items():\n",
    "                band_mask = (freqs >= low) & (freqs <= high)\n",
    "                if not np.any(band_mask):\n",
    "                    band_power = 0.0\n",
    "                else:\n",
    "                    band_power = simps(psd[band_mask], freqs[band_mask])\n",
    "                ch_features[f'{band}'] = band_power\n",
    "            \n",
    "            epoch_features[ch_name] = ch_features\n",
    "            \n",
    "        clean_epochs.append(epoch_features)\n",
    "        \n",
    "    return clean_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c0df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ppg_and_extract_hrv(ppg_data, sfreq):\n",
    "    \"\"\"\n",
    "    Processes raw PPG signal to find Interbeat Intervals (IBIs) and\n",
    "    extracts Heart Rate Variability (HRV) metrics.\n",
    "    \"\"\"\n",
    "    print(f\"Processing PPG data (length {len(ppg_data)} samples) at {sfreq} Hz...\")\n",
    "    \n",
    "    working_data = {}\n",
    "    measures = {}\n",
    "    \n",
    "    try:\n",
    "        # HeartPy's process function handles filtering, peak detection, \n",
    "        # IBI calculation, and feature extraction all in one.\n",
    "        working_data, measures = hp.process(ppg_data, sample_rate=sfreq)\n",
    "        \n",
    "        if 'lf/hf' in measures:\n",
    "            print(f\"Successfully computed HRV. LF/HF Ratio: {measures['lf/hf']:.3f}\")\n",
    "        else:\n",
    "            print(\"HRV computed, but 'lf/hf' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"HeartPy processing failed: {e}\")\n",
    "        \n",
    "    return working_data, measures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86e3f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relative_band_power(band_powers, target_band):\n",
    "    total_power = sum(v for k, v in band_powers.items() if k in ['delta', 'theta', 'alpha', 'beta', 'gamma'])\n",
    "    if total_power == 0:\n",
    "        return 0.0\n",
    "    return band_powers.get(target_band, 0.0) / total_power\n",
    "\n",
    "def normalize_score(value, min_val, max_val):\n",
    "    if value is None or np.isnan(value):\n",
    "        return None\n",
    "    score = ((value - min_val) / (max_val - min_val))\n",
    "    score = max(0.0, min(1.0, score))\n",
    "    return round(score * 100, 2)\n",
    "\n",
    "def interpret_epoch_insights_v1(epoch_features, hrv_measures, channel_names):\n",
    "    final_insights = {\n",
    "        'timestamp': epoch_features.get('start_time_sec'),\n",
    "        'scores': { 'stress': None, 'relaxation': None, 'focus': None },\n",
    "    }\n",
    "    \n",
    "    # --- 1. Stress Score (from PPG) ---\n",
    "    lf_hf_ratio = hrv_measures.get('lf/hf')\n",
    "    if lf_hf_ratio is not None and not np.isnan(lf_hf_ratio):\n",
    "        STRESS_MIN_VAL = 0.5\n",
    "        STRESS_MAX_VAL = 2.5 \n",
    "        final_insights['scores']['stress'] = normalize_score(lf_hf_ratio, STRESS_MIN_VAL, STRESS_MAX_VAL)\n",
    "    \n",
    "    # --- 2. Relaxation Score (from EEG) ---\n",
    "    alpha_channels = [ch for ch in ['TP9', 'TP10'] if ch in channel_names]\n",
    "    if alpha_channels:\n",
    "        total_relative_alpha = 0.0\n",
    "        for ch in alpha_channels:\n",
    "            ch_powers = epoch_features.get(ch, {})\n",
    "            total_relative_alpha += get_relative_band_power(ch_powers, 'alpha')\n",
    "        avg_relative_alpha = total_relative_alpha / len(alpha_channels)\n",
    "        RELAX_MIN_VAL = 0.15 # 15%\n",
    "        RELAX_MAX_VAL = 0.40 # 40%\n",
    "        final_insights['scores']['relaxation'] = normalize_score(avg_relative_alpha, RELAX_MIN_VAL, RELAX_MAX_VAL)\n",
    "\n",
    "    # --- 3. Focus Score (from EEG) ---\n",
    "    focus_channels = [ch for ch in ['AF7', 'AF8'] if ch in channel_names]\n",
    "    if focus_channels:\n",
    "        total_tbr = 0.0\n",
    "        for ch in focus_channels:\n",
    "            ch_powers = epoch_features.get(ch, {})\n",
    "            theta = ch_powers.get('theta', 0.0)\n",
    "            beta = ch_powers.get('beta', 0.0)\n",
    "            if beta > 0:\n",
    "                total_tbr += (theta / beta)\n",
    "        avg_tbr = total_tbr / len(focus_channels)\n",
    "        FOCUS_MIN_VAL = 4.0 # High TBR = Low Focus\n",
    "        FOCUS_MAX_VAL = 1.5 # Low TBR = High Focus\n",
    "        final_insights['scores']['focus'] = normalize_score(avg_tbr, FOCUS_MIN_VAL, FOCUS_MAX_VAL)\n",
    "        \n",
    "    return final_insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29704fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRunning EEG Pre-processing...\")\n",
    "if 'eeg_data' in locals(): # Check if data loaded successfully\n",
    "    filtered_eeg, artifact_mask = preprocess_eeg(eeg_data, \n",
    "                                                 acc_data, \n",
    "                                                 gyro_data, \n",
    "                                                 eeg_sfreq, \n",
    "                                                 channel_names)\n",
    "    print(\"EEG Pre-processing complete.\")\n",
    "    print(f\"{artifact_mask.sum() / len(artifact_mask) * 100:.2f}% of samples flagged as artifacts.\")\n",
    "\n",
    "    # --- EEG Visualization 1: Raw vs. Filtered ---\n",
    "    print(\"\\nPlotting Raw vs. Filtered EEG...\")\n",
    "    time_axis = np.arange(eeg_data.shape[0]) / eeg_sfreq\n",
    "    num_channels = eeg_data.shape[1]\n",
    "\n",
    "    fig, axes = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "    fig.suptitle('Raw vs. Filtered EEG Data', fontsize=16)\n",
    "\n",
    "    for i in range(num_channels):\n",
    "        ax = axes[i]\n",
    "        ch_name = channel_names[i]\n",
    "        \n",
    "        # Plot Raw Data (with offset for clarity)\n",
    "        raw_mean = np.mean(eeg_data[:, i])\n",
    "        ax.plot(time_axis, eeg_data[:, i] - raw_mean, 'b', alpha=0.5, label='Raw (mean-centered)')\n",
    "        \n",
    "        # Plot Filtered Data\n",
    "        ax.plot(time_axis, filtered_eeg[:, i], 'r', alpha=0.8, label='Filtered')\n",
    "        \n",
    "        ax.set_ylabel(f\"{ch_name}\\n(uV)\")\n",
    "        ax.legend(loc='upper right')\n",
    "\n",
    "    axes[-1].set_xlabel('Time (seconds)')\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show() # This will open a plot window\n",
    "\n",
    "\n",
    "    # --- EEG Visualization 2: Filtered Data with Artifacts ---\n",
    "    print(\"\\nPlotting Filtered EEG with Artifact Mask...\")\n",
    "\n",
    "    fig, axes = plt.subplots(num_channels, 1, figsize=(15, 10), sharex=True)\n",
    "    fig.suptitle('Filtered EEG with Detected Artifacts', fontsize=16)\n",
    "\n",
    "    for i in range(num_channels):\n",
    "        ax = axes[i]\n",
    "        ch_name = channel_names[i]\n",
    "        \n",
    "        # Plot Filtered Data\n",
    "        ax.plot(time_axis, filtered_eeg[:, i], 'g', label='Filtered Data')\n",
    "        \n",
    "        # Shade artifact regions\n",
    "        mask_indices = np.where(artifact_mask)[0]\n",
    "        for start in mask_indices:\n",
    "            # This is inefficient for plotting, but fine for 10s\n",
    "            ax.axvspan(start/eeg_sfreq, (start+1)/eeg_sfreq, color='red', alpha=0.2)\n",
    "\n",
    "        ax.set_ylabel(f\"{ch_name}\\n(uV)\")\n",
    "        \n",
    "        # Add a custom legend entry for the artifact shading\n",
    "        if i == 0:\n",
    "            ax.plot([], [], color='red', alpha=0.2, linewidth=10, label='Artifact Detected')\n",
    "        ax.legend(loc='upper right')\n",
    "\n",
    "    axes[-1].set_xlabel('Time (seconds)')\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show() # This will open a second plot window\n",
    "\n",
    "else:\n",
    "    print(\"Skipping EEG processing as data was not loaded.\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Run EEG Feature Extraction\n",
    "# \n",
    "# Now we'll segment the 10-second cleaned signal into smaller epochs (e.g., 2 seconds) and extract the band power features.\n",
    "\n",
    "# %% [code]\n",
    "# ==================================\n",
    "# Cell 7: Run EEG Feature Extraction\n",
    "# ==================================\n",
    "if 'filtered_eeg' in locals(): # Check if previous step ran\n",
    "    epoch_sec = 2.0\n",
    "    overlap_sec = 1.0\n",
    "\n",
    "    print(f\"\\nExtracting EEG features ({epoch_sec}s epochs, {overlap_sec}s overlap)...\")\n",
    "\n",
    "    eeg_features = extract_eeg_features(filtered_eeg, \n",
    "                                      artifact_mask, \n",
    "                                      eeg_sfreq, \n",
    "                                      channel_names, \n",
    "                                      epoch_sec, \n",
    "                                      overlap_sec)\n",
    "\n",
    "    print(f\"\\nExtracted features from {len(eeg_features)} clean epochs.\")\n",
    "\n",
    "    if eeg_features:\n",
    "        print(\"\\n--- Example features from first clean epoch ---\")\n",
    "        print(json.dumps(eeg_features[0], indent=2))\n",
    "    else:\n",
    "        print(\"No clean epochs were found in this 10-second sample.\")\n",
    "else:\n",
    "    print(\"Skipping EEG feature extraction as pre-processing did not run.\")\n",
    "    eeg_features = [] # Define as empty list to avoid errors\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Run PPG Pipeline & Visualize Results\n",
    "# \n",
    "# Next, we process the PPG data. \n",
    "# \n",
    "# **CRITICAL NOTE:** Your data sample is only ~10 seconds long. **This is too short for a reliable HRV Frequency-Domain (LF/HF) analysis.** # \n",
    "# Standard HRV frequency analysis requires a minimum of 60 seconds. The `heartpy` library will likely fail to calculate the `lf/hf` ratio, or it will be `NaN`. This is **expected behavior**. For a real application, you would buffer 60 seconds of PPG data *before* running this analysis.\n",
    "\n",
    "# %% [code]\n",
    "# ==================================\n",
    "# Cell 8: Run PPG Pipeline\n",
    "# ==================================\n",
    "if 'ppg_data' in locals():\n",
    "    # --- PPG Visualization 1: Raw Data ---\n",
    "    print(\"\\nPlotting Raw PPG Data...\")\n",
    "    ppg_time_axis = np.arange(ppg_data.shape[0]) / ppg_sfreq\n",
    "\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    plt.title(\"Raw PPG Signal\")\n",
    "    plt.plot(ppg_time_axis, ppg_data, label=\"Raw PPG\")\n",
    "    plt.xlabel(\"Time (seconds)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.legend()\n",
    "    plt.show() # This will open a third plot window\n",
    "\n",
    "    # --- Run PPG Pipeline ---\n",
    "    ppg_working_data, ppg_measures = preprocess_ppg_and_extract_hrv(ppg_data, ppg_sfreq)\n",
    "\n",
    "    # --- PPG Visualization 2: HeartPy Plotter ---\n",
    "    if ppg_working_data and 'filtered' in ppg_working_data:\n",
    "        print(\"\\nPlotting HeartPy Processing Results...\")\n",
    "        try:\n",
    "            hp.plotter(ppg_working_data, ppg_measures, figsize=(15, 6))\n",
    "            plt.show() # This will open a fourth plot window\n",
    "        except Exception as e:\n",
    "            print(f\"HeartPy plotter failed: {e}. (Often due to no peaks found in short signal)\")\n",
    "    else:\n",
    "        print(\"HeartPy processing failed, skipping plot.\")\n",
    "\n",
    "    print(\"\\n--- Key PPG/HRV Measures (from 10s sample) ---\")\n",
    "    print(f\"  BPM (mean): {ppg_measures.get('bpm', 'N/A')}\")\n",
    "    print(f\"  RMSSD (Time Domain HRV): {ppg_measures.get('rmssd', 'N/A')}\")\n",
    "    print(f\"  LF/HF Ratio (Freq Domain): {ppg_measures.get('lf/hf', 'N/A')} <-- SEE NOTE ABOVE\")\n",
    "else:\n",
    "    print(\"Skipping PPG processing as data was not loaded.\")\n",
    "    ppg_measures = {} # Define as empty dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a162ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- FINAL INSIGHTS (from V1 Engine) ---\")\n",
    "all_insights = []\n",
    "if 'eeg_features' in locals() and 'ppg_measures' in locals():\n",
    "    for epoch in eeg_features:\n",
    "        insight = interpret_epoch_insights_v1(epoch, ppg_measures, channel_names)\n",
    "        all_insights.append(insight)\n",
    "        \n",
    "    print(json.dumps(all_insights, indent=2))\n",
    "else:\n",
    "    print(\"Skipping insights engine as features were not extracted.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
